model:
  - generation: ministral3
    run_name: ministral-3-14b-instruct-2512
    model_name: Ministral-3-14B-Instruct-2512
    device: auto
    # Match the HF sample: pixel_values are moved to bf16 on GPU.
    dtype: bfloat16
    trust_remote_code: false
    # Local checkpoint path (edit if yours differs)
    path: /mnt/shared-storage-user/ai4good2-share/models/mistralai/Ministral-3-14B-Instruct-2512
    generation_config:
      do_sample: false
      max_new_tokens: 512

progress_equalize_evaluators: true

# NOTE: Existing evaluators in this repo are text-only. This config wires them up
# to keep the run schema consistent, but multimodal evaluation will require
# multimodal-aware evaluators/datasets.
evaluators:
  - type: tellme
    run_name: tellme
    batch_size: 16
    token_position: -1
    layer_ratio: 0.6666
    dataset:
      name: tellme/beaver_tails_filtered
      test_path: dataset/tellme/test.csv
    summarizer:
      type: tellme

  - type: xboundary
    run_name: x-boundary
    batch_size: 8
    max_length: 1024
    save_metrics_json: true
    save_tsne: true
    dataset:
      name: xboundary/diagnostic
      data_dir: dataset/xboundary
      # Match original X-Boundary default: --num_samples (per class)
      num_samples_per_class: 200
    summarizer:
      type: xboundary
      select_by: boundary_ratio
      include_both_selections: true

  - type: spin
    run_name: spin
    # Match original SPIN default: --nsamples
    nsamples: 128
    seed: 0
    q: 5e-7               # top-q ratio per dataset
    target_module: mlp    # mlp | self_attn | all
    per_layer: true
    per_module: false
    device: cuda
    save_coupling_plot: true
    dataset:
      name: spin/csv_bundle
      dataset1_name: privacy
      dataset2_name: fairness
      dataset1_path: dataset/spin/beaver_train330k_privacy_safe_1k.csv
      dataset2_path: dataset/spin/beaver_train330k_fairness_safe_1k.csv
    summarizer:
      type: spin
      top_layers: 5
      
summarizer:
  type: combined

