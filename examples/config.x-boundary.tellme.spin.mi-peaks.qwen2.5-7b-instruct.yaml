model:
  generation: qwen2.5
  model_name: Qwen2.5-7B-Instruct
  device: auto
  load_in_8bit: false
  path: /path/to/Qwen2.5-7B-Instruct
  dtype: bfloat16
  trust_remote_code: true
  load_tokenizer: true
  # Reference generation parameters (deterministic)
  generation_config:
    do_sample: false
    temperature: 0.0
    top_p: 1.0
    top_k: 0
    repetition_penalty: 1.0

evaluators:
  - type: tellme
    run_name: tellme
    batch_size: 16
    token_position: -1
    layer_ratio: 0.6666
    dataset:
      name: tellme/beaver_tails_filtered
      test_path: dataset/tellme/test.csv
    summarizer:
      type: tellme

  - type: xboundary
    run_name: x-boundary
    batch_size: 8
    max_length: 1024
    save_metrics_json: true
    save_tsne: true
    dataset:
      name: xboundary/diagnostic
      data_dir: dataset/xboundary
      # Match original X-Boundary default: --num_samples (per class)
      num_samples_per_class: 200
    summarizer:
      type: xboundary
      select_by: boundary_ratio
      include_both_selections: true

  - type: spin
    run_name: spin
    # Match original SPIN default: --nsamples
    nsamples: 128
    seed: 0
    q: 5e-7               # top-q ratio per dataset
    target_module: mlp    # mlp | self_attn | all
    per_layer: true
    per_module: false
    device: cuda
    save_coupling_plot: true
    dataset:
      name: spin/csv_bundle
      dataset1_name: privacy
      dataset2_name: fairness
      dataset1_path: dataset/spin/beaver_train330k_privacy_safe_1k.csv
      dataset2_path: dataset/spin/beaver_train330k_fairness_safe_1k.csv
    summarizer:
      type: spin
      top_layers: 5


  - type: mi-peaks
    run_name: mi-peaks
    # Use last layer by default for portability across backbones.
    # (MI-Peaks paper examples often use layer=31 for 32-layer models; Qwen2.5-7B has fewer layers.)
    target_layer: -1
    # Optional: cap how many examples to run MI over (evaluator-level cap).
    # If omitted, the evaluator uses the dataset size (after dataset truncation above).
    sample_num: 10
    # Activation extraction
    max_new_tokens: 512
    token_position: -1
    # MI estimator (matches MI-Peaks default)
    sigma: 50.0
    ktype: gaussian
    # Peak summary
    top_k: 20
    top_tokens: 15
    # optionally, to reuse *existing* MI-Peaks artifacts for strict reproduction:
    artifact_root: /root/code/MI-Peaks/src
    reuse_cache: false
    dataset:
      name: mi-peaks/math_train_12k
      sample_num: 10
      csv_path: dataset/mi_peaks/math_train_12k.csv

# Run-level summarizer that aggregates all evaluators
summarizer:
  type: combined
