model:
  generation: qwen2.5
  model_name: Qwen2.5-7B-Instruct
  device: cuda
  load_in_8bit: false
  path: /root/models/Qwen2.5-7B-Instruct
  # Match the checkpoint's native dtype when possible; use "auto" if unsure.
  dtype: bfloat16
  trust_remote_code: true
  load_tokenizer: true
  # Reference generation parameters (deterministic)
  generation_config:
    do_sample: false
    temperature: 0.0
    top_p: 1.0
    top_k: 0
    repetition_penalty: 1.0

progress_equalize_evaluators: true


evaluators:
  - type: tellme
    run_name: tellme
    batch_size: 16
    token_position: -1
    layer_ratio: 0.6666
    dataset:
      name: tellme/beaver_tails_filtered
      test_path: /root/code/LLM-Diagnose-Framework/dataset/tellme/test.csv

      
    summarizer:
      type: tellme
  - type: xboundary
    run_name: x-boundary
    batch_size: 8
    max_length: 1024
    save_metrics_json: true
    save_tsne: true
    dataset:
      name: xboundary/diagnostic
      data_dir: /root/code/LLM-Diagnose-Framework/dataset/xboundary
      num_samples_per_class: 50
    summarizer:
      type: xboundary
      select_by: boundary_ratio
      include_both_selections: true

# Run-level summarizer that aggregates all evaluators (tellme + x-boundary)
summarizer:
  type: combined
