<div align="center">
<picture>
  <source media="(prefers-color-scheme: dark)" srcset="logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="logo-light.svg">
    <img alt="DeepScan Logo" src="logo-dark.svg" width="300">
  </picture>
</div>
<div style="height: 50px;"></div>


# DeepScan: é¢å‘å¤§è¯­è¨€æ¨¡å‹çš„è¯Šæ–­æ¡†æ¶ ğŸ”¬

é¢å‘å¤§è¯­è¨€æ¨¡å‹ä¸å¤šæ¨¡æ€å¤§æ¨¡å‹çš„å¯æ‰©å±•è¯Šæ–­æ¡†æ¶ï¼Œå›´ç»•"æ³¨å†Œ â†’ é…ç½® â†’ æ‰§è¡Œ â†’ æ±‡æ€»"è®¾è®¡ï¼Œæä¾›ç»Ÿä¸€çš„ Runnerã€è¯„ä¼°å™¨ä¸æ±‡æ€»å™¨æŠ½è±¡ï¼Œä¾¿äºå¿«é€Ÿæ­å»ºæˆ–å®šåˆ¶è¯Šæ–­æµæ°´çº¿ã€‚

## âœ¨ ç‰¹æ€§

- **ğŸ“¦ æ¨¡å‹æ³¨å†Œè¡¨**ï¼šæ³¨å†Œå’Œç®¡ç†æ¨¡å‹å®ä¾‹ï¼Œæ”¯æŒ Qwenã€Llamaã€Mistralã€Gemmaã€GLMã€InternLMã€InternVL ç­‰
- **ğŸš€ ç»Ÿä¸€æ¨¡å‹æ¥å£**ï¼šä¸€è‡´çš„ `generate`/`chat` æŠ½è±¡ï¼Œè·¨æ¨¡å‹æ—ç»Ÿä¸€ä½¿ç”¨
- **ğŸ“Š æ•°æ®é›†æ³¨å†Œè¡¨**ï¼šæ³¨å†Œå’Œç®¡ç†æ•°æ®é›†å®ä¾‹ï¼Œæ”¯æŒå¤šç§æ•°æ®æ ¼å¼
- **âš™ï¸ é…ç½®ç®¡ç†**ï¼šä» YAML/JSON æ–‡ä»¶åŠ è½½å’Œç®¡ç†é…ç½®
- **ğŸ” å¯æ‰©å±•Evaluator**ï¼šå†…ç½®å¤šç§è¯Šæ–­Evaluatorï¼š
  - **TELLME**ï¼šç”¨æŒ‡æ ‡é‡åŒ–è¡¨å¾ä¸­ä¸åŒæ¦‚å¿µçš„è§£è€¦ç¨‹åº¦
  - **X-Boundary**ï¼šè¯Šæ–­éšè¡¨ç¤ºç©ºé—´ï¼šå®‰å…¨/æœ‰å®³/è¾¹ç•Œå‡ ä½•å…³ç³»
  - **MI-Peaks**ï¼šåŸºäºäº’ä¿¡æ¯è¿½è¸ªç”Ÿæˆä¸­æ¨ç†è¡¨å¾ä¿¡æ¯æ¼”åŒ–
  - **SPIN**ï¼šåˆ†æå…¬å¹³ã€éšç§ç­‰å®‰å…¨ç›®æ ‡é—´çš„æ½œåœ¨å†²çª
- **ğŸ“ å¯å®šåˆ¶Summarizer**ï¼šèšåˆå’Œæ ¼å¼åŒ–ä¸åŒåŸºå‡†çš„è¯„ä¼°ç»“æœ
- **ğŸ“ˆ è¿›åº¦è·Ÿè¸ª**ï¼šå†…ç½®è¿›åº¦å›è°ƒï¼Œç›‘æ§é•¿æ—¶é—´è¿è¡Œçš„Evaluator
- **ğŸ”Œ æ’ä»¶æ¶æ„**ï¼šæ˜“äºæ‰©å±•è‡ªå®šä¹‰Evaluatorå’ŒSummarizer
- **ğŸ’» CLI æ”¯æŒ**ï¼šæ— éœ€ç¼–å†™ä»£ç å³å¯ä»å‘½ä»¤è¡Œè¿è¡Œè¯„ä¼°

## ğŸ“¥ å®‰è£…

**æœ€å°å®‰è£…**ï¼ˆä»…æ ¸å¿ƒä¾èµ–ï¼‰ï¼š
```bash
pip install -e .
```

**æ¨èå®‰è£…**ï¼ˆåŒ…å«å¤§å¤šæ•°ç”¨ä¾‹æ‰€éœ€çš„å¸¸ç”¨ä¾èµ–ï¼‰ï¼š
```bash
pip install -e ".[default]"
```

**å¼€å‘æ¨¡å¼å®‰è£…**ï¼š
```bash
pip install -e ".[dev]"
```

**å…¶ä»–å¯é€‰ä¾èµ–**ï¼š

```bash
# ğŸ¤– æ¨¡å‹è¿è¡Œå™¨ä¾èµ–
pip install -e ".[qwen]"          # Qwen æ¨¡å‹
pip install -e ".[glm]"           # GLM æ¨¡å‹
pip install -e ".[ministral3]"    # Ministral 3 (å¤šæ¨¡æ€) æ¨¡å‹

# ğŸ”¬ è¯„ä¼°å™¨ä¾èµ–
pip install -e ".[tellme]"        # TELLME è¯„ä¼°å™¨ + æŒ‡æ ‡æ ˆ
pip install -e ".[xboundary]"     # X-Boundary è¯„ä¼°å™¨ + å¯è§†åŒ–æ ˆ
pip install -e ".[mi_peaks]"     # MI-Peaks è¯„ä¼°å™¨

# ğŸ ä¾¿æ·æ‰©å±•
pip install -e ".[all]"           # æ‰€æœ‰è¯„ä¼°å™¨ä¾èµ– (tellme + xboundary + mi_peaks)

# ğŸŒ API æœåŠ¡å™¨ï¼ˆå†…éƒ¨ä½¿ç”¨ - å¼€æºæ ¸å¿ƒç‰ˆæœ¬ä¸åŒ…å«ï¼‰
pip install -e ".[api]"           # FastAPI + Uvicorn
```

## ğŸš€ å¿«é€Ÿä¸Šæ‰‹

### ğŸ¯ ä»é…ç½®æ–‡ä»¶ç«¯åˆ°ç«¯è¿è¡Œï¼ˆä»»ä½•è¯„ä¼°å™¨ï¼‰

**Python APIï¼š**
```python
from deepscan import run_from_config

# YAML/JSON æˆ–åŒ…å« model/dataset/evaluator éƒ¨åˆ†çš„å­—å…¸
results = run_from_config("examples/config.tellme.yaml")

# å¸¦è¿›åº¦å›è°ƒ
def on_progress(completed, total, desc):
    print(f"{completed}/{total}: {desc}")

results = run_from_config(
    "examples/config.tellme.yaml",
    on_progress_update=on_progress,
    output_dir="results",
    run_id="my_experiment",
)
```

**CLI**ï¼ˆæ— éœ€ç¼–å†™ Python ä»£ç ï¼‰ï¼š
```bash
# âœ… åŸºæœ¬ç”¨æ³•
python -m deepscan.run --config examples/config.tellme.yaml --output-dir runs

# ğŸ·ï¸ ä½¿ç”¨è‡ªå®šä¹‰è¿è¡Œ ID
python -m deepscan.run --config examples/config.tellme.yaml --output-dir runs --run-id experiment_001

# ğŸ” å¹²è¿è¡Œï¼ˆéªŒè¯é…ç½®è€Œä¸åŠ è½½æ¨¡å‹/æ•°æ®é›†ï¼‰
python -m deepscan.run --config examples/config.tellme.yaml --dry-run

# ğŸ’¾ å¯é€‰ï¼šåŒæ—¶å°†å•ä¸ªåˆå¹¶çš„ JSON å†™å…¥æŒ‡å®šä½ç½®
python -m deepscan.run --config examples/config.tellme.yaml --output results.json
```

### 1. æ³¨å†Œæ¨¡å‹å’Œæ•°æ®é›†ï¼ˆå…¨å±€æ³¨å†Œè¡¨ï¼‰ğŸ“

#### ğŸ”§ æ³¨å†Œå•ä¸ªæ¨¡å‹

```python
from deepscan.registry.model_registry import get_model_registry
from deepscan.registry.dataset_registry import get_dataset_registry

# é‡è¦ï¼šä½¿ç”¨å…¨å±€æ³¨å†Œè¡¨ï¼Œä»¥ä¾¿ `run_from_config()` å¯ä»¥æ‰¾åˆ°æ‚¨çš„æ¡ç›®
model_registry = get_model_registry()
dataset_registry = get_dataset_registry()

@model_registry.register_model("gpt2")
def create_gpt2():
    from transformers import GPT2LMHeadModel
    return GPT2LMHeadModel.from_pretrained("gpt2")

@dataset_registry.register_dataset("glue_sst2")
def create_sst2():
    from datasets import load_dataset
    return load_dataset("glue", "sst2", split="test")
```

#### æ³¨å†Œæ¨¡å‹ç³»åˆ—ï¼ˆä¾‹å¦‚ Qwenï¼‰ğŸ—ï¸


**é€‰é¡¹ 1ï¼šæŒ‰ä¸–ä»£æ³¨å†Œï¼ˆæ¨èï¼‰** â­

```python
from deepscan.registry.model_registry import get_model_registry

registry = get_model_registry()

@registry.register_model(
    "qwen3",
    model_family="qwen",
    model_generation="qwen3",
)
def create_qwen3(model_name: str = "Qwen3-8B", device: str = "cuda", **kwargs):
    """åˆ›å»ºæŒ‡å®šåç§°çš„ Qwen3 æ¨¡å‹ã€‚"""
    from transformers import AutoModelForCausalLM
    
    model_paths = {
        "Qwen3-0.6B": "Qwen/Qwen3-0.6B",
        "Qwen3-1.5B": "Qwen/Qwen3-1.5B",
        "Qwen3-2B": "Qwen/Qwen3-2B",
        "Qwen3-8B": "Qwen/Qwen3-8B",
        "Qwen3-14B": "Qwen/Qwen3-14B",
        "Qwen3-32B": "Qwen/Qwen3-32B",
    }
    
    if model_name not in model_paths:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
    
    return AutoModelForCausalLM.from_pretrained(
        model_paths[model_name],
        device_map=device,
        **kwargs
    )

# ç”¨æ³•ï¼š
runner = registry.get_model("qwen3", model_name="Qwen3-8B", device="cuda")
```

**é€‰é¡¹ 2ï¼šä½¿ç”¨ä¸–ä»£å‰ç¼€æ³¨å†Œå•ä¸ªæ¨¡å‹** ğŸ”‘

```python
@registry.register_model(
    "qwen3/Qwen3-8B",
    model_family="qwen",
    model_generation="qwen3",
    model_name="Qwen3-8B",
)
def create_qwen3_8b(device: str = "cuda", **kwargs):
    from transformers import AutoModelForCausalLM
    return AutoModelForCausalLM.from_pretrained(
        "Qwen/Qwen3-8B",
        device_map=device,
        **kwargs
    )

# ç”¨æ³•ï¼š
runner = registry.get_model("qwen3/Qwen3-8B", device="cuda")
```

**ğŸ’¡ ä¸ºä»€ä¹ˆæŒ‰ä¸–ä»£ç»„ç»‡ï¼Ÿ** ä¸åŒçš„ Qwen ä¸–ä»£ï¼ˆqwenã€qwen2ã€qwen3ï¼‰å³ä½¿åœ¨ç›¸åŒçš„å‚æ•°æ•°é‡ä¸‹ä¹Ÿå¯èƒ½å…·æœ‰ä¸åŒçš„æ¶æ„ã€åˆ†è¯å™¨å’Œé…ç½®ã€‚

**é€‰é¡¹ 3ï¼šä½¿ç”¨é¢„æ³¨å†Œæ¨¡å‹ï¼ˆæ¨èï¼‰** â­

Qwen æ¨¡å‹åœ¨å¯¼å…¥æ¡†æ¶æ—¶ä¼šè‡ªåŠ¨æ³¨å†Œï¼š

```python
from deepscan.registry.model_registry import get_model_registry

# æ¨¡å‹å·²æ³¨å†Œ - ç›´æ¥ä½¿ç”¨ï¼
registry = get_model_registry()
runner = registry.get_model("qwen3", model_name="Qwen3-8B", device="cuda")
```

æˆ–è€…ç®€å•åœ°å¯¼å…¥æ¡†æ¶ï¼Œæ¨¡å‹å³å¯ä½¿ç”¨ï¼š

```python
import deepscan  # Qwen æ¨¡å‹è‡ªåŠ¨æ³¨å†Œ
from deepscan.registry.model_registry import get_model_registry

registry = get_model_registry()
runner = registry.get_model("qwen3", model_name="Qwen3-8B", device="cuda")
```

æŸ¥çœ‹ `deepscan/models/` äº†è§£æ¨¡å‹å®ç°ï¼ŒæŸ¥çœ‹ `examples/` äº†è§£ç«¯åˆ°ç«¯è¯„ä¼°æµæ°´çº¿ã€‚

#### é¢„æ³¨å†Œèµ„æºï¼ˆæ¨¡å‹ + æ•°æ®é›†ï¼‰ğŸ

æ¡†æ¶é™„å¸¦å¼€ç®±å³ç”¨çš„æ³¨å†Œé¡¹ï¼Œåœ¨æ‚¨ `import deepscan` æ—¶ä¼šè‡ªåŠ¨åŠ è½½ï¼š

**ğŸ¤– æ¨¡å‹**ï¼ˆæŸ¥çœ‹ `deepscan/models/` äº†è§£å®ç°ï¼‰ï¼š
- **Qwen**: qwen / qwen2 / qwen2.5 / qwen3 å˜ä½“
- **Llama**: Llama 2/3 å˜ä½“
- **Mistral**: Mistral å’Œ Ministral3ï¼ˆå¤šæ¨¡æ€ï¼‰
- **Gemma**: Gemma å’Œ Gemma3ï¼ˆå¤šæ¨¡æ€ï¼‰
- **GLM**: GLM-4 ç³»åˆ—
- **InternLM**: InternLM2/3 å˜ä½“
- **InternVL**: InternVL3.5ï¼ˆå¤šæ¨¡æ€ï¼‰

**ğŸ“Š æ•°æ®é›†**ï¼š
- BeaverTailsï¼ˆHF æ•°æ®é›†ï¼‰
- `tellme/beaver_tails_filtered`ï¼ˆCSV åŠ è½½å™¨ï¼‰
- `xboundary/diagnostic`ï¼ˆX-Boundary è¯Šæ–­æ•°æ®é›†ï¼‰

```python
import deepscan
from deepscan.registry.model_registry import get_model_registry
from deepscan.registry.dataset_registry import get_dataset_registry

model_registry = get_model_registry()
dataset_registry = get_dataset_registry()

# ä½¿ç”¨ä»»ä½•å·²æ³¨å†Œçš„æ¨¡å‹
model = model_registry.get_model("qwen3", model_name="Qwen3-8B", device="cuda")
# æˆ– Llamaã€Mistral ç­‰

# ä½¿ç”¨å·²æ³¨å†Œçš„æ•°æ®é›†
dataset = dataset_registry.get_dataset("tellme/beaver_tails_filtered", test_path="/path/to/test.csv")
```

> ğŸ’¡ å†…ç½®æ•°æ®é›†åŠ è½½å™¨ä¾èµ–äº Hugging Face `datasets`ï¼ˆåŒ…å«åœ¨æ ¸å¿ƒä¾èµ–ä¸­ï¼‰ã€‚

è¦ä½¿ç”¨é€šè¿‡ `datasets.save_to_disk` ä¿å­˜çš„å‰¯æœ¬ï¼Œä¼ é€’æœ¬åœ°è·¯å¾„ï¼š

```python
dataset = dataset_registry.get_dataset(
    "beaver_tails",
    split="330k_train",
    path="/path/to/BeaverTails",
)
```

### ğŸƒ æ¨¡å‹è¿è¡Œå™¨

æ¨¡å‹æ³¨å†Œè¡¨æŸ¥æ‰¾ç°åœ¨è¿”å›ä¸€ä¸ª**æ¨¡å‹è¿è¡Œå™¨**â€”â€”ä¸€ä¸ªæš´éœ²ç»Ÿä¸€ `generate()` æ¥å£å¹¶ä¿ç•™åº•å±‚ Hugging Face æ¨¡å‹/åˆ†è¯å™¨çš„å¯¹è±¡ã€‚

```python
from deepscan.models.base_runner import GenerationRequest, PromptMessage, PromptContent
from deepscan.registry.model_registry import get_model_registry

runner = get_model_registry().get_model(
    "qwen3",
    model_name="Qwen3-8B",
    device="cuda",
)

# å¿«é€Ÿæ–‡æœ¬ç”Ÿæˆ
response = runner.generate("ç”¨ä¸¤å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯æ³¨å†Œè¡¨æ¨¡å¼ã€‚")
print(response.text)

# å¸¦ç»“æ„åŒ–æ¶ˆæ¯çš„èŠå¤©å¼æç¤º
chat_request = GenerationRequest.from_messages(
    [
        PromptMessage(role="system", content=[PromptContent(text="ä½ æ˜¯ä¸€ä½æ•°å­¦å¯¼å¸ˆã€‚")]),
        PromptMessage(role="user", content=[PromptContent(text="å¸®æˆ‘å› å¼åˆ†è§£ x^2 + 5x + 6ã€‚")]),
    ],
    temperature=0.1,
    max_new_tokens=128,
)
chat_response = runner.generate(chat_request)
print(chat_response.text)
```

è¿è¡Œå™¨é€šè¿‡ `runner.model` / `runner.tokenizer` ä¿ç•™åŸå§‹æ¨¡å‹/åˆ†è¯å™¨çš„è®¿é—®ï¼Œä»¥ä¾¿ç°æœ‰è¯Šæ–­ä»£ç åœ¨éœ€è¦æ—¶ä»å¯è®¿é—®åº•å±‚ APIã€‚

### 2. åŠ è½½é…ç½® âš™ï¸

```python
from deepscan import ConfigLoader

# ä»æ–‡ä»¶åŠ è½½
config = ConfigLoader.from_file("config.yaml")

# æˆ–ä»å­—å…¸åˆ›å»º
config = ConfigLoader.from_dict({
    "model": {"generation": "qwen3", "model_name": "Qwen3-8B", "device": "cuda"},
    "dataset": {"name": "beaver_tails", "split": "330k_train"},
    "evaluator": {"type": "tellme", "batch_size": 4},
})
```

### 3. åˆ›å»ºå’Œä½¿ç”¨è¯„ä¼°å™¨ ğŸ”

è¯„ä¼°å™¨é€šå¸¸é€šè¿‡ `run_from_config` ä½¿ç”¨ï¼Œä½†ä¹Ÿå¯ä»¥ä»¥ç¼–ç¨‹æ–¹å¼ä½¿ç”¨ï¼š

```python
from deepscan.evaluators.registry import get_evaluator_registry
from deepscan.registry.model_registry import get_model_registry
from deepscan.registry.dataset_registry import get_dataset_registry

# è·å–æ³¨å†Œè¡¨
evaluator_registry = get_evaluator_registry()
model_registry = get_model_registry()
dataset_registry = get_dataset_registry()

# ä»æ³¨å†Œè¡¨åˆ›å»ºè¯„ä¼°å™¨
evaluator = evaluator_registry.create_evaluator(
    "tellme",
    batch_size=4,
    layer_ratio=0.6666,
    token_position=-1,
)

# è·å–æ¨¡å‹å’Œæ•°æ®é›†
model = model_registry.get_model("qwen3", model_name="Qwen3-8B", device="cuda")
dataset = dataset_registry.get_dataset("tellme/beaver_tails_filtered", test_path="/path/to/test.csv")

# è¿è¡Œè¯„ä¼°ï¼ˆé€šå¸¸é€šè¿‡ run_from_config å®Œæˆï¼‰
# results = evaluator.evaluate(model, dataset, ...)
```

### 4. è¿›åº¦å›è°ƒ ğŸ“ˆ

ä½¿ç”¨å›è°ƒç›‘æ§è¯„ä¼°è¿›åº¦ï¼š

```python
def on_start(total: Optional[int], description: str):
    print(f"å¼€å§‹: {description} ({total} é¡¹)")

def on_update(completed: int, total: Optional[int], description: str):
    if total:
        pct = (completed / total) * 100
        print(f"è¿›åº¦: {completed}/{total} ({pct:.1f}%) - {description}")

def on_done(completed: int, total: Optional[int], description: str):
    print(f"å®Œæˆ: {description}")

results = run_from_config(
    "config.yaml",
    on_progress_start=on_start,
    on_progress_update=on_update,
    on_progress_done=on_done,
)
```

### 5. åˆ›å»ºè‡ªå®šä¹‰è¯„ä¼°å™¨ ğŸ› ï¸

```python
from deepscan.evaluators.base import BaseEvaluator
from deepscan.evaluators.registry import get_evaluator_registry

class CustomEvaluator(BaseEvaluator):
    def evaluate(self, model, dataset, **kwargs):
        # æ‚¨çš„è‡ªå®šä¹‰è¯„ä¼°é€»è¾‘
        results = {}
        # ... å®ç° ...
        return results

# æ³¨å†Œè¯„ä¼°å™¨
registry = get_evaluator_registry()
registry.register_evaluator("custom_eval")(CustomEvaluator)

# åœ¨é…ç½®ä¸­æˆ–ä»¥ç¼–ç¨‹æ–¹å¼ä½¿ç”¨
evaluator = registry.create_evaluator("custom_eval", param1=value1)
```

### 6. æ±‡æ€»ç»“æœ ğŸ“Š

```python
from deepscan.summarizers.base import BaseSummarizer

class SimpleSummarizer(BaseSummarizer):
    def summarize(self, results, benchmark=None, **kwargs):
        # æœ€å°ç¤ºä¾‹ï¼šä¿ç•™ä¸€å°éƒ¨åˆ†é”®
        return {
            "benchmark": benchmark,
            "keys": sorted(results.keys()),
        }

summarizer = SimpleSummarizer(name="simple")

summary = summarizer.summarize(results, benchmark="beaver_tails")

# æ ¼å¼åŒ–ä¸º markdown
report = summarizer.format_report(summary, format="markdown")
print(report)
```

## ğŸ—ï¸ æ¶æ„

### æ ¸å¿ƒç»„ä»¶

1. **ğŸ“¦ æ³¨å†Œè¡¨ç³»ç»Ÿ** (`deepscan/registry/`)
   - `BaseRegistry`: é€šç”¨æ³¨å†Œè¡¨æ¨¡å¼
   - `ModelRegistry`: æ¨¡å‹æ³¨å†Œå’Œæ£€ç´¢
   - `DatasetRegistry`: æ•°æ®é›†æ³¨å†Œå’Œæ£€ç´¢

2. **âš™ï¸ é…ç½®** (`deepscan/config/`)
   - `ConfigLoader`: åŠ è½½å’Œç®¡ç† YAML/JSON é…ç½®
   - æ”¯æŒç‚¹å·è®¿é—®åµŒå¥—é…ç½®
   - åˆå¹¶å¤šä¸ªé…ç½®

3. **ğŸ” è¯„ä¼°å™¨** (`deepscan/evaluators/`)
   - `BaseEvaluator`: æ‰€æœ‰è¯„ä¼°å™¨çš„æŠ½è±¡åŸºç±»
   - `TellMeEvaluator`: BeaverTails ä¸Šçš„è§£è€¦åº¦æŒ‡æ ‡
   - `XBoundaryEvaluator`: å®‰å…¨è¾¹ç•Œåˆ†æ
   - `MiPeaksEvaluator`: æ¨¡å‹å†…çœå’Œå³°å€¼åˆ†æ
   - `SpinEvaluator`: è‡ªå¯¹å¼ˆå¾®è°ƒè¯„ä¼°
   - `EvaluatorRegistry`: è¯„ä¼°å™¨ç±»çš„æ³¨å†Œè¡¨

4. **ğŸ“ æ±‡æ€»å™¨** (`deepscan/summarizers/`)
   - `BaseSummarizer`: æ‰€æœ‰æ±‡æ€»å™¨çš„æŠ½è±¡åŸºç±»
   - `SummarizerRegistry`: æ±‡æ€»å™¨ç±»çš„æ³¨å†Œè¡¨
   - å¤šç§è¾“å‡ºæ ¼å¼ï¼ˆdictã€JSONã€Markdownã€æ–‡æœ¬ï¼‰

## ğŸ”§ æ‰©å±•æ¡†æ¶

### â• æ·»åŠ æ–°è¯„ä¼°å™¨

1. ç»§æ‰¿ `BaseEvaluator`
2. å®ç° `evaluate` æ–¹æ³•
3. ä½¿ç”¨è¯„ä¼°å™¨æ³¨å†Œè¡¨æ³¨å†Œ

```python
from deepscan.evaluators.base import BaseEvaluator
from deepscan.evaluators.registry import get_evaluator_registry

class MyEvaluator(BaseEvaluator):
    def evaluate(self, model, dataset, **kwargs):
        # æ‚¨çš„è¯„ä¼°é€»è¾‘
        results = {}
        # ... å®ç° ...
        return results

# æ³¨å†Œ
registry = get_evaluator_registry()
registry.register_evaluator("my_evaluator")(MyEvaluator)
```

### â• æ·»åŠ æ–°æ±‡æ€»å™¨

1. ç»§æ‰¿ `BaseSummarizer`
2. å®ç° `summarize` æ–¹æ³•
3. ä½¿ç”¨æ±‡æ€»å™¨æ³¨å†Œè¡¨æ³¨å†Œ

```python
from deepscan.summarizers.base import BaseSummarizer
from deepscan.summarizers.registry import get_summarizer_registry

class MySummarizer(BaseSummarizer):
    def summarize(self, results, benchmark=None, **kwargs):
        # æ‚¨çš„æ±‡æ€»é€»è¾‘
        return {"summary": "..."}

# æ³¨å†Œ
registry = get_summarizer_registry()
registry.register_summarizer("my_summarizer")(MySummarizer)
```

## ğŸ“‹ é…ç½®ç¤ºä¾‹æ–‡ä»¶

```yaml
# ğŸ“ æœ€å° TELLME é£æ ¼é…ç½®ï¼ˆæŸ¥çœ‹ `examples/config.tellme.yaml` äº†è§£å®Œæ•´ç‰ˆæœ¬ï¼‰
model:
  generation: qwen3
  model_name: Qwen3-8B
  device: cuda
  dtype: float16
  # å¯é€‰ï¼šæŒ‡å‘æœ¬åœ°æ£€æŸ¥ç‚¹ç›®å½•ä»¥é¿å…ä¸‹è½½
  # path: /path/to/models--Qwen--Qwen3-8B

dataset:
  name: tellme/beaver_tails_filtered
  test_path: /path/to/test.csv
  # train_path: /path/to/train.csv
  # max_rows: 400

evaluator:
  type: tellme
  batch_size: 4
  layer_ratio: 0.6666
  token_position: -1
```

## ğŸ“š ç¤ºä¾‹

æŸ¥çœ‹ `examples/` ç›®å½•äº†è§£å®Œæ•´ä½¿ç”¨ç¤ºä¾‹ï¼š

**ğŸ” è¯„ä¼°å™¨ï¼š**
- `config.tellme.yaml`: TELLME è§£è€¦åº¦æŒ‡æ ‡
- `config.xboundary.yaml`: X-Boundary å®‰å…¨åˆ†æ
- `config.mi_peaks.yaml`: MI-Peaks å†…çœ
- `config.spin.yaml`: SPIN è¯„ä¼°

**ğŸ”— ç»„åˆé…ç½®ï¼š**
- `config.xboundary.tellme-qwen2.5-7b-instruct.yaml`: åŒä¸€æ¨¡å‹ä¸Šçš„å¤šä¸ªè¯„ä¼°å™¨

## ğŸ’» å¼€å‘

```bash
# ğŸ“¦ ä»¥å¼€å‘æ¨¡å¼å®‰è£…
pip install -e ".[dev]"

# âœ… è¿è¡Œæµ‹è¯•
pytest

```

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£å¦‚ä½•è´¡çŒ®çš„æŒ‡å—ã€‚